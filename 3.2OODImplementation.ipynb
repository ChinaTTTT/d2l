{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 类里定义 模型 损失函数 和 优化器\n",
    "DataModule 类里定义 数据加载器 dataLoader\n",
    "Trainer 类组合，在硬件上训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#往类里加功能，甚至是已经创建的实例\n",
    "#用到了wrapper函数，这个函数返回的是一个函数，这个函数的参数是一个函数，这个函数的功能是把这个函数加到类里，装饰器的功能\n",
    "def add_to_class(Class):\n",
    "    '''Register functions as methods in created class'''\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)#obj是函数\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self) -> None:\n",
    "        self.b = 1\n",
    "a = A()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class attrribute \"b\" is  1\n"
     ]
    }
   ],
   "source": [
    "@add_to_class(A)\n",
    "def do(self):\n",
    "    print('class attrribute \"b\" is ',self.b)\n",
    "\n",
    "a.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.a=1, self.b=2, self.c=3\n",
      "There is no self.c True\n"
     ]
    }
   ],
   "source": [
    "class HyperParameters:\n",
    "    def save_hyperparameters(self, ignore=[]):\n",
    "        raise NotImplemented\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.a=1, self.b=2, self.c=5\n",
      "There is no self.c True\n"
     ]
    }
   ],
   "source": [
    "class B(d2l.HyperParameters):\n",
    "    def __init__(self, a, b, c) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['c'])\n",
    "        print(f'self.a={a}, self.b={b}, self.c={c}', )\n",
    "        print(f'There is no self.c', not hasattr(self, 'c'))\n",
    "\n",
    "b = B(a=1,b=2,c=5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBoard(d2l.HyperParameters):\n",
    "    def __init__(self,  xlabel=None, ylabel=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'],\n",
    "                 fig=None, axes=None, figsize=(3.5, 2.5), display=True) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "    def draw(self, x, y, label, every_n=1):\n",
    "        raise NotImplemented    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = d2l.ProgressBoard('x')\n",
    "for x in np.arange(0, 10, 0.1):\n",
    "    board.draw(x, np.sin(x), 'sin', every_n=10)\n",
    "    board.draw(x, np.cos(x), 'cos', every_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(nn.Module, d2l.HyperParameters):\n",
    "    def __init__(self, plot_train_epoch=2, plot_valid_per_epoch=1) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.board = ProgressBoard()\n",
    "        \n",
    "    def loss(self, y_hat, y):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def forward(self, X):\n",
    "        assert hasattr(self, 'net'),'Neural network is not defined'\n",
    "        return self.net(X)\n",
    "    \n",
    "    def plot(self, key, value, train):\n",
    "        assert hasattr(self, 'trainer'), 'Trainer is not inited'\n",
    "        self.board.xlabel = 'epoch'\n",
    "        if train:\n",
    "            \n",
    "            x = self.trainer.train_epoch_idx / \\\n",
    "                self.trainer.num_train_batches\n",
    "            n = self.trainer.num_train_batches /\\\n",
    "                self.plot_train_epoch#n是每个epoch画几次\n",
    "        \n",
    "        else:\n",
    "            x = self.trainer.epoch + 1\n",
    "            n = self.trainer.num_val_batches / \\\n",
    "                self.plot_valid_per_epoch\n",
    "        \n",
    "        self.board.draw(x, value.to(d2l.cpu()).detach().numpy(),\n",
    "                        ('train_' if train else 'val_') + key,\n",
    "                        every_n=int(n))\n",
    "    def training_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('loss', l, train=True)\n",
    "        return l\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('loss', l, train=False)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(d2l.HyperParameters):\n",
    "    def __init__(self, root='..\\data', num_workers=4):\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def get_dataloader(self, train):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(train=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader(train=False)\n",
    "    \n",
    "\n",
    "class Trainer(d2l.HyperParameters):\n",
    "    def __init__(self, max_epochs, num_gpus) -> None:\n",
    "        super().__init__()   \n",
    "        self.save_hyperparameters()\n",
    "        assert num_gpus == 0 or torch.cuda.is_available(), 'No GPU is available'\n",
    "    \n",
    "    def prepare_data(self, data):\n",
    "        self.train_loader = data.train_dataloader()\n",
    "        self.val_loader = data.val_dataloader()\n",
    "        self.num_train_batches = len(self.train_loader)\n",
    "        self.num_val_batches = len(self.val_loader) if self.val_loader else 0\n",
    "        \n",
    "    def prepare_model(self, model):\n",
    "        self.trainer = self\n",
    "        model.board.xlim = [0, self.max_epochs]\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def fit(self, model,data):\n",
    "        self.prepare_data(data)\n",
    "        self.prepare_model(model)\n",
    "        self.optim = model.configure_optimizers()\n",
    "        self.epoch = 0\n",
    "        self.train_batch_idx = 0\n",
    "        self.val_batch_idx = 0\n",
    "        for self.epoch in range(self.max_epochs):\n",
    "            self.fit_epoch()\n",
    "    \n",
    "    def fit_epoch(self):\n",
    "        raise NotImplementedError            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
