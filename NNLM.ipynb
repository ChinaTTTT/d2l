{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#做一个遍历的字典\n",
    "sentences = ['i like cat', 'i love coffee', 'i hate milk']\n",
    "sentences_list = \" \".join(sentences).split() # ['i', 'like', 'cat', 'i', 'love'. 'coffee',...]\n",
    "vocab = list(set(sentences_list)) # 去重复\n",
    "word2idx = {w:i for i, w in enumerate(vocab)}\n",
    "idx2word = {i:w for i, w in enumerate(vocab)}\n",
    "\n",
    "V = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(sentences):\n",
    "    input_data = []\n",
    "    target_data = []#预测下一个单词\n",
    "    #句子的向量化tmp\n",
    "    for sen in sentences:\n",
    "        sen = sen.split()\n",
    "        input_tmp = [word2idx[w] for w in sen[:-1] ]#前n-1个单词\n",
    "        target_tmp = word2idx[sen[-1]]#预测的最后一个单词\n",
    "\n",
    "        input_data.append(input_tmp)\n",
    "        target_data.append(target_tmp) \n",
    "    return input_data, target_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data,target_data =  make_data(sentences)\n",
    "\n",
    "input_data = torch.LongTensor(input_data)\n",
    "target_data =  torch.LongTensor(target_data)\n",
    "dataset = Data.TensorDataset(input_data, target_data)\n",
    "loader = Data.DataLoader(dataset, 2, True)#数据源，batch_size, shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "m = 2\n",
    "n_step = 2 #输入的单词数目\n",
    "n_hidden = 2 #隐藏层的神经元个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.C = nn.Embedding(V, m)\n",
    "        self.H = nn.Parameter(torch.randn(n_step * m, n_hidden).type(dtype))  #dtype = torch.FloatTensor\n",
    "        self.d = nn.Parameter(torch.randn(n_hidden).type(dtype))\n",
    "        self.b = nn.Parameter(torch.randn(V).type(dtype))\n",
    "        self.W = nn.Parameter(torch.randn(n_step * m, V).type(dtype))\n",
    "        self.U = nn.Parameter(torch.randn(n_hidden, V).type(dtype))\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        X: [batch_size, n_step]\n",
    "\n",
    "        '''\n",
    "        X = self.C(X)\n",
    "        X = X.view(-1, n_step * m) # [batch_size, n_step * m] 三维压二维\n",
    "        hidden_out = torch.tanh(X.mm(self.H)+self.d) # [batch_size, n_hidden]\n",
    "        output = self.b + X.mm(self.W) + hidden_out.mm(self.U) # [batch_size, V]\n",
    "        return output\n",
    "\n",
    "model = NNLM()\n",
    "optim = optim.Adam(model.parameters(),lr=1e-3) #定义优化器\n",
    "criterion = nn.CrossEntropyLoss()   #定义损失函数\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1000, loss: 0.000041961\n",
      "epoch: 1000, loss: 0.000020265\n",
      "epoch: 2000, loss: 0.000013709\n",
      "epoch: 2000, loss: 0.000007629\n",
      "epoch: 3000, loss: 0.000003695\n",
      "epoch: 3000, loss: 0.000004768\n",
      "epoch: 4000, loss: 0.000001371\n",
      "epoch: 4000, loss: 0.000001669\n",
      "epoch: 5000, loss: 0.000000596\n",
      "epoch: 5000, loss: 0.000000477\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5000):\n",
    "    for i, (batch_x, batch_y) in enumerate(loader):\n",
    "        pred = model(batch_x)\n",
    "        loss = criterion(pred, batch_y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (epoch+1) % 1000 == 0:\n",
    "            print(\"epoch: {}, loss: {:.9f}\".format(epoch+1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'like'], ['i', 'love'], ['i', 'hate']] -> ['cat', 'coffee', 'milk']\n"
     ]
    }
   ],
   "source": [
    "#Pred\n",
    "predict = model(input_data).data.max(1, keepdim=True)[1]\n",
    "print([sen.split()[:2] for sen in sentences], '->', [idx2word[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. CPU will be used.\n",
      "Calculation completed.\n",
      "Embedding calculation completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU will be used.\")\n",
    "    # 获取当前 GPU 设备\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. CPU will be used.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# 创建一个随机张量并将其移动到 GPU\n",
    "tensor = torch.randn(10000, 10000).to(device)\n",
    "\n",
    "# 执行一些计算\n",
    "result = tensor @ tensor.T\n",
    "\n",
    "print(\"Calculation completed.\")\n",
    "print(\"Embedding calculation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
